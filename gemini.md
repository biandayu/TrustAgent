# 项目计划书：类 Claude Desktop 跨平台 AI 聊天应用

## 1. 项目愿景与目标

开发一款功能强大、界面现代化、响应迅速的桌面 AI 聊天应用，旨在成为开发者、研究人员和高级用户的首选工具。应用将支持跨平台（Windows, macOS, Linux），允许用户无缝接入并管理多个自定义的大语言模型（LLM），并集成前沿的 AI Agent 能力（MCP）。

**核心目标:**

*   **高性能体验**: 提供一个轻量、快速、低资源占用的原生桌面体验。
*   **高度可定制**: 用户可以轻松配置和切换不同的 LLM 服务，包括云端 API 和本地运行的模型。
*   **强大的 Agent 功能**: 不仅仅是聊天，更能通过 MCP (Multi-Content Prompt / Agent Protocol) 执行复杂的、多步骤的任务。
*   **安全与隐私**: 用户数据（如 API Key、聊天记录）在本地安全存储，不依赖云端。

## 2. 核心功能规划

*   **跨平台支持**: 一套代码库，编译生成 Windows (`.msi`), macOS (`.dmg`) 和 Linux (`.AppImage`, `.deb`) 安装包。
*   **现代化聊天界面**:
    *   支持 Markdown 渲染和代码高亮。
    *   流式响应，文字逐字显示。
    *   多会话管理和切换。
*   **自定义 LLM Provider**:
    *   内置对主流服务（OpenAI, Gemini, Anthropic）的支持。
    *   支持连接本地运行的模型（如通过 Ollama 或 `llama.cpp`）。
    *   提供图形化设置界面，用于增删改查 LLM 配置。
*   **安全配置管理**:
    *   API Key 等敏感信息在本地加密存储。
*   **MCP / Agent Protocol 实现**:
    *   能够接收复杂任务指令。
    *   在 UI 中可视化任务的执行步骤（如 "思考中...", "正在使用工具: 文件读取"）。
    *   **应用启动时自动扫描并连接配置文件中定义的所有 MCP Server**。
*   **本地历史记录**:
    *   所有聊天记录保存在本地数据库中。
    *   未来可支持全文搜索。
*   **系统日志**:
    *   所有关键操作（如服务启动、API 调用、错误）均有日志记录，方便调试和追踪问题。

## 3. 技术选型

| 层面 | 技术 | 理由 |
| :--- | :--- | :--- |
| **核心框架** | **Tauri** | 轻量（使用系统原生 WebView）、安全（Rust 后端）、高性能、跨平台。完胜 Electron。 |
| **后端逻辑** | **Rust** | 内存安全、无畏并发、顶级性能。是构建健壮、高效桌面应用的理想选择。 |
| **前端界面** | **React + TypeScript** | 拥有庞大的生态系统和成熟的组件库，开发效率高，能快速构建复杂的 UI。 |
| **UI/样式** | **Tailwind CSS + Shadcn/ui** | 提供原子化的 CSS 类，能快速构建高度自定义且美观的界面。 |
| **前端状态管理** | **Zustand** | 轻量、简单、易于使用的 React 状态管理库。 |
| **关键 Rust 库** | `tokio`, `reqwest`, `serde`, `async-openai`, `rmcp`, `tracing`, `tracing-subscriber`, `tauri-plugin-store` | 构成了与 LLM API 通信、本地推理、Agent 功能、日志和安全存储的坚实基础。 |

## 4. 系统架构设计

应用采用经典的前后端分离架构，通过 Tauri 的 API 进行通信。

1.  **UI 层 (Frontend - React/TS)**
    *   负责所有用户交互界面，如聊天窗口、设置页面。
    *   通过 Tauri API 向后端发送命令式请求（如 `run_agent_task`）。
    *   监听从后端发出的事件，以更新 UI（如流式消息、Agent 状态）。

2.  **核心逻辑层 (Backend - Rust)**
    *   处理所有业务逻辑，是应用的大脑。
    *   **LLM Provider 抽象层**: 定义一个通用的 `LLMProvider` Trait（接口），所有模型服务都实现此接口。
    *   **配置管理器**: 负责安全地读写和加密用户配置。
    *   **MCP/Agent 核心**: 实现任务（Task）和步骤（Step）的执行逻辑。
    *   **日志系统**: 在应用启动时初始化，将日志输出到用户特定目录下的 `logs` 文件夹。
    *   通过 `emit` 机制向前端广播事件。

3.  **通信层 (Tauri API)**
    *   **Invoke**: 前端调用 Rust 函数。
    *   **Emit/Listen**: 后端向前端发送事件流。

## 5. 项目现状与核心功能实现

本章节旨在描述项目当前已完成的核心功能，这些功能构成了应用的骨架。

### 5.1. 已实现的核心 Agent 功能

项目已经从一个简单的聊天应用，升级为具备核心 Agent 能力的智能工具。关键的断层已被弥合：

1.  **Agent 执行逻辑已实现**: 后端 `agent.rs` 模块中已实现了一个完整的 Agent 执行器。它能够接收用户的指令和一份动态的可用工具列表，通过与 LLM 交互进行决策，并判断何时以及如何使用 `rmcp` 协议来调用外部工具。

2.  **前后端功能已打通**: MCP 工具管理界面与主聊天界面不再是孤岛。用户可以在 `McpToolsMenu` 组件中通过复选框动态启用或禁用工具，这些选择会随同用户的聊天消息一同发送给后端 Agent，从而实现了在聊天中动态调用工具的能力。

3.  **实时 Agent 状态反馈**: 前后端通信已升级为包含实时事件流的模式。当 Agent 在后端执行任务时（例如“思考中”或“正在使用工具”），它会通过 `window.emit()` 向前端实时发送进度事件，前端 UI 会监听这些事件并将其可视化地展示给用户。

### 5.2. 已实现的基础设施增强

为支持核心 Agent 功能并提升应用的健壮性和用户体验，以下基础设施已完成实现：

1.  **启动时自动加载 MCP 服务**: 应用在启动时会自动读取配置文件中的 `mcp_servers` 列表，并在后台为每个服务异步启动一个子进程。随后，应用通过 `rmcp` 连接到这些进程，获取它们提供的工具列表，并实时更新到前端 UI。

2.  **全局日志系统**: 应用已集成 `tracing`、`tracing-subscriber` 和 `tracing-appender`，实现了结构化的全局日志系统。所有关键操作（应用启动、MCP 服务连接、工具调用、API 请求、错误等）的日志都会被记录到用户配置目录下的 `logs` 文件夹中，极大地提升了开发调试和后期维护的效率。

## 6. 开发路线图 (已更新)

1.  **阶段一：项目搭建和基础 UI (已完成)**
    *   使用 `create-tauri-app` 初始化项目。
    *   搭建静态的聊天界面布局。

2.  **阶段二：核心聊天功能 (已完成)**
    *   在 Rust 后端实现对单一模型（如 OpenAI）的 API 调用。
    *   实现了基本的多会话管理。

3.  **阶段三：支持自定义 LLM 和 MCP 发现 (已完成)**
    *   完成了设置页面的 UI 和后端逻辑，实现配置的加密存储。
    *   实现了 MCP Server 的启动、停止和工具列表的发现功能。

4.  **阶段四：集成 MCP/Agent 核心功能 (已完成)**
    *   **子任务 1: 实现日志与自动加载**: **已完成**。
    *   **子任务 2: 实现后端 Agent 核心逻辑**: **已完成**。
    *   **子任务 3: 实现 Agent 状态事件流**: **已完成**。
    *   **子任务 4: 打通前后端交互**: **已完成**。

5.  **阶段五：完善和打包 (当前焦点)**
    *   实现本地聊天记录的全文搜索。
    *   进行全面的测试、Bug 修复和性能优化。
    *   为三大平台构建和打包应用。

## 7. 总结与下一步

本计划书描述了一个技术先进且功能强大的 AI Agent 应用。当前，项目已经完成了所有核心功能的开发，从一个简单的聊天应用成功升级为一个具备基本 Agent 能力的智能工具。

**下一步的工作重心将是完成**阶段五**的收尾工作，包括功能完善、性能优化和多平台打包发布。**

## 8. 已实现的核心功能模块详解

以下是当前版本中已稳定实现的核心功能模块。这些功能共同保证了应用的健壮性和优秀的用户体验。

### 8.1. 对话历史记录管理 (Dialogue History Management)

对话历史记录功能已得到完整实现，其核心机制如下：

*   **基于文件的存储**: 每个独立的聊天会话（`ChatSession`）被序列化为 JSON 格式，并作为一个单独的 `.json` 文件存储。
*   **存储路径**: 这些会话文件位于用户数据目录下的 `.chats` 子目录中（例如 `.../TrustAgent/data/.chats/<session_id>.json`）。
*   **完整的 CRUD 操作**: 支持完整的会话生命周期管理：
    *   **创建 (Create)**: 用户可以随时创建新的聊天会话。
    *   **读取 (Read)**: 应用启动时会加载所有历史会话，并允许用户切换查看。
    *   **更新 (Update)**: 会话标题可以被重命名。
    *   **删除 (Delete)**: 用户可以彻底删除不再需要的会话。
*   **会话与消息结构**: 每个会话（`ChatSession`）和消息（`ChatMessage`）都有清晰的结构定义，包含ID、标题、时间戳、角色和内容等。
*   **实时持久化**: 对会话的任何更改（如新增消息、重命名标题、删除会话）都会被实时同步到文件系统。

**未来展望**: 可考虑将此功能从 JSON 文件存储升级为更高效的本地数据库（如 SQLite），以便为全文搜索等高级功能打下基础。

### 8.2. 上下文窗口管理 (Context Window Management)

为确保应用在不限制对话次数的情况下依然能够稳定运行并有效管理上下文，实现了“滑动窗口”机制。这可以避免因会话历史过长而导致数据量过于庞大，或超出大语言模型（LLM）的上下文长度限制（Token Limit）。

**实现策略**:

在向 LLM 发送请求时，并非发送全部历史消息，而是采用以下策略：

*   **滑动窗口**: 在 `agent.rs` 中，仅保留最近的 N 条消息（当前设置为45条），动态截取最新的消息传递给模型。
*   **系统提醒**: 为了防止模型在长对话中“忘记”自己的能力，在每次工具调用后，会向上下文中注入一条系统消息，提醒模型其当前可用的工具集。

智能的上下文管理是让 Agent 能够进行长期、复杂对话的关键。
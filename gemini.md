# 项目计划书：类 Claude Desktop 跨平台 AI 聊天应用

## 1. 项目愿景与目标

开发一款功能强大、界面现代化、响应迅速的桌面 AI 聊天应用，旨在成为开发者、研究人员和高级用户的首选工具。应用将支持跨平台（Windows, macOS, Linux），允许用户无缝接入并管理多个自定义的大语言模型（LLM），并集成前沿的 AI Agent 能力（MCP）。

**核心目标:**

*   **高性能体验**: 提供一个轻量、快速、低资源占用的原生桌面体验。
*   **高度可定制**: 用户可以轻松配置和切换不同的 LLM 服务，包括云端 API 和本地运行的模型。
*   **强大的 Agent 功能**: 不仅仅是聊天，更能通过 MCP (Multi-Content Prompt / Agent Protocol) 执行复杂的、多步骤的任务。
*   **安全与隐私**: 用户数据（如 API Key、聊天记录）在本地安全存储，不依赖云端。

## 2. 核心功能规划

*   **跨平台支持**: 一套代码库，编译生成 Windows (`.msi`), macOS (`.dmg`) 和 Linux (`.AppImage`, `.deb`) 安装包。
*   **现代化聊天界面**:
    *   支持 Markdown 渲染和代码高亮。
    *   流式响应，文字逐字显示。
    *   多会话管理和切换。
*   **自定义 LLM Provider**:
    *   内置对主流服务（OpenAI, Gemini, Anthropic）的支持。
    *   支持连接本地运行的模型（如通过 Ollama 或 `llama.cpp`）。
    *   提供图形化设置界面，用于增删改查 LLM 配置。
*   **安全配置管理**:
    *   API Key 等敏感信息在本地加密存储。
*   **MCP / Agent Protocol 实现**:
    *   能够接收复杂任务指令。
    *   在 UI 中可视化任务的执行步骤（如 "思考中...", "正在使用工具: 文件读取"）。
    *   **应用启动时自动扫描并连接配置文件中定义的所有 MCP Server**。
*   **本地历史记录**:
    *   所有聊天记录保存在本地数据库中。
    *   未来可支持全文搜索。
*   **系统日志**:
    *   所有关键操作（如服务启动、API 调用、错误）均有日志记录，方便调试和追踪问题。

## 3. 技术选型推荐

| 层面 | 技术 | 理由 |
| :--- | :--- | :--- |
| **核心框架** | **Tauri** | 轻量（使用系统原生 WebView）、安全（Rust 后端）、高性能、跨平台。完胜 Electron。 |
| **后端逻辑** | **Rust** | 内存安全、无畏并发、顶级性能。是构建健壮、高效桌面应用的理想选择。 |
| **前端界面** | **React + TypeScript** | 拥有庞大的生态系统和成熟的组件库，开发效率高，能快速构建复杂的 UI。 |
| **UI/样式** | **Tailwind CSS + Shadcn/ui** | 提供原子化的 CSS 类，能快速构建高度自定义且美观的界面。 |
| **前端状态管理** | **Zustand** | 轻量、简单、易于使用的 React 状态管理库。 |
| **关键 Rust 库** | `tokio`, `reqwest`, `serde`, `async-openai`, `rmcp`, `tracing`, `tracing-subscriber`, `tauri-plugin-store` | 构成了与 LLM API 通信、本地推理、Agent 功能、日志和安全存储的坚实基础。 |

## 4. 系统架构设计

应用采用经典的前后端分离架构，通过 Tauri 的 API 进行通信。

1.  **UI 层 (Frontend - React/TS)**
    *   负责所有用户交互界面，如聊天窗口、设置页面。
    *   通过 Tauri API 向后端发送命令式请求（如 `run_agent_task`）。
    *   监听从后端发出的事件，以更新 UI（如流式消息、Agent 状态）。

2.  **核心逻辑层 (Backend - Rust)**
    *   处理所有业务逻辑，是应用的大脑。
    *   **LLM Provider 抽象层**: 定义一个通用的 `LLMProvider` Trait（接口），所有模型服务都实现此接口。
    *   **配置管理器**: 负责安全地读写和加密用户配置。
    *   **MCP/Agent 核心**: 实现任务（Task）和步骤（Step）的执行逻辑。
    *   **日志系统**: 在应用启动时初始化，将日志输出到用户特定目录下的 `logs` 文件夹。
    *   通过 `emit` 机制向前端广播事件。

3.  **通信层 (Tauri API)**
    *   **Invoke**: 前端调用 Rust 函数。
    *   **Emit/Listen**: 后端向前端发送事件流。

## 5. 当前状态评估与设计改进

本章节旨在记录当前项目的真实状态以及根据最新讨论形成的设计决策。

### 5.1. 当前状态评估 (截至 2025-08-14)

项目已完成基础框架搭建，但核心 Agent 功能存在明显断层：

1.  **Agent 执行逻辑缺失**: 后端已通过 `rmcp` 实现了 MCP 工具的**发现**（能列出工具有哪些），但完全没有实现工具的**使用**。处理用户输入的依然是直连 OpenAI 的简单聊天功能，Agent 的决策和执行循环尚未开发。
2.  **功能孤岛化**: MCP 工具管理界面与主聊天界面是两个独立功能，用户无法在聊天中实际选用或激活已发现的工具。
3.  **缺少实时反馈**: 前后端通信是一次性的“请求-响应”模式，无法满足 Agent 可视化执行步骤所需的实时事件流。

### 5.2. 设计改进要点

为解决上述问题并完善应用，确定以下设计改进：

1.  **启动时自动加载 MCP 服务**: 为提升用户体验，应用在启动时应自动执行以下操作：
    *   读取配置文件中的 `mcp_servers` 列表。
    *   为每个服务在后台异步启动一个子进程。
    *   通过 `rmcp` 连接到该进程，获取其提供的工具（Tools）列表。
    *   将所有获取到的工具状态实时更新到前端 UI。
2.  **实现全局日志系统**: 为便于开发调试和后期维护，需引入结构化日志。
    *   **技术栈**: 采用 `tracing` 及 `tracing-subscriber`, `tracing-appender` crates。
    *   **日志路径**: 日志文件将存储在用户配置目录下的 `logs` 文件夹中（例如 `C:/Users/<user>/AppData/Roaming/TrustAgent/logs`），与 `configuration` 和 `data` 目录平级。
    *   **日志内容**: 覆盖所有关键路径，包括应用启动、MCP 服务连接、工具调用、API 请求、错误处理等。

## 6. 开发路线图 (已修订)

1.  **阶段一：项目搭建和基础 UI (已完成)**
    *   使用 `create-tauri-app` 初始化项目。
    *   搭建静态的聊天界面布局。

2.  **阶段二：核心聊天功能 (已完成)**
    *   在 Rust 后端实现对单一模型（如 OpenAI）的 API 调用。
    *   实现了基本的多会话管理。

3.  **阶段三：支持自定义 LLM 和 MCP 发现 (已完成)**
    *   完成了设置页面的 UI 和后端逻辑，实现配置的加密存储。
    *   实现了 MCP Server 的启动、停止和工具列表的发现功能。

4.  **阶段四：集成 MCP/Agent 核心功能 (当前焦点)**
    *   **子任务 1: 实现日志与自动加载**:
        *   在 Rust 后端引入 `tracing` 日志系统。
        *   实现应用启动时，根据配置自动在后台启动所有 MCP Server 并获取工具列表。
    *   **子任务 2: 实现后端 Agent 核心逻辑**:
        *   创建新的 Agent 模块 (`agent.rs`)。
        *   设计并实现一个 Agent 执行器，它能接收用户指令和一份可用的工具列表。
        *   该执行器通过与 LLM 交互进行决策，判断何时以及如何使用 `rmcp::client::Client` 来调用工具。
    *   **子任务 3: 实现 Agent 状态事件流**:
        *   改造后端的 Tauri 命令，使其在 Agent 执行任务时，能通过 `window.emit()` 向前端实时发送进度事件（如 `agent_thinking`, `tool_using` 等）。
    *   **子任务 4: 打通前后端交互**:
        *   在前端 `McpToolsMenu` 组件中增加工具启用/禁用的 UI（如复选框）。
        *   将用户在聊天时“激活”的工具列表随同消息一起发送给后端 Agent。
        *   前端监听并处理来自后端的 Agent 状态事件，并将其可视化地展示出来。

5.  **阶段五：完善和打包 (未来)**
    *   实现本地聊天记录的全文搜索。
    *   进行全面的测试、Bug 修复和性能优化。
    *   为三大平台构建和打包应用。

## 7. 总结与下一步

本计划书提出了一个清晰、可行且技术先进的方案。当前，项目的核心挑战和任务是完成**阶段四**的工作，即从一个简单的聊天应用升级为一个具备基本 Agent能力的智能工具。

**建议立即批准此修订计划，并着手开始第四阶段的开发工作。**

## 8. 回忆录：需要重新实现或改进的重要功能

根据对项目早期版本的代码分析，以下是几个在当前迭代中需要特别关注、重新实现或予以改进的核心功能。这些功能对于保证应用的健壮性和用户体验至关重要。

### 8.1. 对话历史记录管理 (Dialogue History Management)

此前的版本中，对话历史记录功能已经比较完善，其核心机制如下：

*   **基于文件的存储**: 每个独立的聊天会话（`ChatSession`）被序列化为 JSON 格式，并作为一个单独的 `.json` 文件存储。
*   **存储路径**: 这些会话文件位于用户数据目录下的 `.chats` 子目录中（例如 `.../TrustAgent/data/.chats/<session_id>.json`）。
*   **完整的 CRUD 操作**: 支持完整的会话生命周期管理：
    *   **创建 (Create)**: 用户可以随时创建新的聊天会话。
    *   **读取 (Read)**: 应用启动时会加载所有历史会话，并允许用户切换查看。
    *   **更新 (Update)**: 会话标题可以被重命名。
    *   **删除 (Delete)**: 用户可以彻底删除不再需要的会话。
*   **会话结构**: 每个会话（`ChatSession`）包含一个唯一的 `id`、用户可自定义的 `title`、创建和更新时间戳，以及一个包含所有消息（`ChatMessage`）的向量。
*   **消息结构**: 每条消息（`ChatMessage`）都包含 `role` (system, user, or assistant)、`content` 和 `timestamp`。
*   **实时持久化**: 对会话的任何更改（如新增消息、重命名标题、删除会话）都会被实时或在会话切换时同步到文件系统。

**建议**: 当前版本应恢复此功能，并可考虑将其从 JSON 文件存储升级为更高效的本地数据库（如 SQLite），以便为未来的全文搜索等高级功能打下基础。

### 8.2. 上下文窗口管理 (Context Window Management)

为确保应用在不限制对话次数的情况下依然能够稳定运行并有效管理上下文，必须实现“滑动窗口”机制。这可以避免因会话历史过长而导致数据量过于庞大，或超出大语言模型（LLM）的上下文长度限制（Token Limit）。

**实现策略**:

在向 LLM 发送请求时，不能发送全部历史消息，而应采用以下机制之一：

*   **滑动窗口**: 仅保留最近的 N 条消息，或动态截取总 Token 数量不超过模型限制的最新消息。
*   **摘要机制 (可选)**: 对于非常长的对话，可以考虑使用一个专门的 LLM 调用来动态地将旧消息总结成摘要，并将其作为“系统提示”的一部分，以保留长期记忆。

智能的上下文管理是让 Agent 能够进行长期、复杂对话的关键。
